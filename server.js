// server.js — Premium phone agent (human-sounding, one-question turns, low-latency)
// Pipeline: Twilio Media Streams (μ-law 8k) -> Deepgram (ASR) -> OpenAI (extraction + NLG) -> Make (READ/CREATE/DELETE/FAQ) -> ElevenLabs (TTS)

"use strict";

const express = require("express");
const http = require("http");
const { WebSocketServer } = require("ws");
const fetch = (...args) => import("node-fetch").then(({ default: f }) => f(...args));

// ---------- ENV & CONSTANTS ----------
const PORT = process.env.PORT || 10000;
const LOCAL_TZ = process.env.LOCAL_TZ || "America/New_York";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
const DG_API_KEY = process.env.DEEPGRAM_API_KEY || "";
const ELEVEN_API_KEY = process.env.ELEVEN_API_KEY || "";
const ELEVEN_VOICE_ID = process.env.ELEVEN_VOICE_ID || "";

// MAKE webhooks
const MAKE_CREATE = process.env.MAKE_CREATE || "https://hook.us2.make.com/7hd4nxdrgytwukxw57cwyykhotv6hxrm";
const MAKE_READ   = process.env.MAKE_READ   || "https://hook.us2.make.com/6hmur673mpqw4xgy2bhzx4be4o32ziax";
const MAKE_DELETE = process.env.MAKE_DELETE || "https://hook.us2.make.com/noy0e27knj7e1jlomtznw34z246i3xtv";

// Agent prompt (externalized). Paste your long prompt into AGENT_PROMPT env on Render.
const FALLBACK_PROMPT = `
You are a friendly, human-sounding AI receptionist for Old Line Barbershop.
Your job is to answer the phone, sound natural, and help customers with the same tasks a real receptionist would handle.

Core Responsibilities
- Greet callers warmly and always say the business name right away. Example: “Hi, thanks for calling Old Line Barbershop. How can I help you today?”
- Answer common questions clearly and directly (hours, pricing, services, location, etc.).
- Handle scheduling: booking, rescheduling, and cancellations.

Rules for Conversation
- Use short, natural sentences (<= ~20 words). Ask AT MOST ONE question per turn.
- Avoid repeating the same wording; vary phrasing naturally.
- Only greet once at the start of the call; never greet again mid-call.
- Give brief status acks (“Got it — let me check the schedule.”). If the caller says “hello?” while you’re checking, reassure briefly.
- If silence persists, give ONE gentle reprompt related to the current step (no greeting). Never echo the same question back-to-back; rephrase if needed.

Booking Order (always follow):
1) Ask service (haircut, beard trim, combo).
2) Ask preferred date/time (interpret in ${LOCAL_TZ}). If vague (“morning/anytime”), propose a nearest open slot and ask if it works.
3) Check availability. If taken, suggest the closest two alternatives (earlier and later).
4) After confirming availability, ask for name and phone number (use caller ID if provided; confirm it first).
5) Finalize the booking.

Policy
- Only book Mon–Fri 9 AM–5 PM (closed weekends) in ${LOCAL_TZ}. Never double-book.
- Keep FAQs separate from booking. Do not enter booking unless caller explicitly asks to book/reschedule/cancel, or clearly agrees after an FAQ.
- FAQs examples:
  Hours: “We’re open Monday–Friday, 9 to 5, closed weekends. Want me to help you book a time?”
  Pricing: “A haircut is $30, a beard trim is $15, or $40 for both. Want to schedule one?”
  Services: “We offer haircuts, beard trims, and combos. Want me to check availability?”
  Location: “We’re at 123 Blueberry Lane. Want to book a visit?”
- If you don’t know: “I’m not sure about that, let me transfer you to someone who can help.” Then end the call.

Booking Details
- Event Title = [Service] – [Customer Name]
- Event Time = [Start] to [Start + 30min]
- Description = Name, Phone, Service
- If caller ID/metadata provides a phone number, read it and ask if it’s OK to use.

Confirmation & Wrap-Up
- Restate all details and confirm phone number, then: “You’re all set.” Thank them, say goodbye, and hang up immediately.

Tone
- Friendly, professional, natural. One short line at a time. Every caller-facing line must be generated by you (no canned phrasing).
`.trim();

const AGENT_PROMPT = process.env.AGENT_PROMPT ? String(process.env.AGENT_PROMPT) : FALLBACK_PROMPT;

// ---------- LOGGING ----------
const log = (...a) => console.log(new Date().toISOString(), "-", ...a);
const err = (...a) => console.error(new Date().toISOString(), "!", ...a);

// ---------- TIME HELPERS ----------
function nowContext() { return { nowISO: new Date().toISOString(), tz: LOCAL_TZ }; }
function pretty(dtISO, tz = LOCAL_TZ) {
  try {
    return new Intl.DateTimeFormat("en-US", {
      timeZone: tz, year: "numeric", month: "short", day: "2-digit",
      hour: "numeric", minute: "2-digit"
    }).format(new Date(dtISO));
  } catch { return dtISO; }
}
function isBusinessHours(dtISO, tz = LOCAL_TZ) {
  const d = new Date(dtISO);
  if (isNaN(d.getTime())) return false;
  const dayShort = new Intl.DateTimeFormat("en-US", { weekday: "short", timeZone: tz }).format(d);
  const hour = Number(new Intl.DateTimeFormat("en-US", { hour: "numeric", hour12: false, timeZone: tz }).format(d));
  const isMonFri = ["Mon","Tue","Wed","Thu","Fri"].includes(dayShort);
  return isMonFri && hour >= 9 && hour < 17;
}

// ---------- μ-law -> PCM16 ----------
function ulawByteToPcm16(u) {
  u = ~u & 0xff;
  const sign = u & 0x80;
  const exponent = (u >> 4) & 0x07;
  const mantissa = u & 0x0f;
  let sample = (((mantissa << 3) + 0x84) << (exponent + 2)) - 0x84 * 4;
  if (sign) sample = -sample;
  if (sample > 32767) sample = 32767;
  if (sample < -32768) sample = -32768;
  return sample;
}
function ulawBufferToPCM16LEBuffer(ulawBuf) {
  const out = Buffer.alloc(ulawBuf.length * 2);
  for (let i = 0; i < ulawBuf.length; i++) out.writeInt16LE(ulawByteToPcm16(ulawBuf[i]), i * 2);
  return out;
}

// ---------- DEEPGRAM REALTIME ----------
function startDeepgram({ onOpen, onPartial, onFinal, onError, onAny }) {
  const WebSocket = require("ws");
  if (!DG_API_KEY) { log("(!) No DEEPGRAM_API_KEY — ASR disabled."); return null; }

  const url = "wss://api.deepgram.com/v1/listen"
    + "?encoding=linear16&sample_rate=8000&channels=1"
    + "&model=nova-2-phonecall&interim_results=true&smart_format=true"
    + "&language=en-US&endpointing=150"; // tighter endpoint for faster turns

  const dg = new WebSocket(url, { headers: { Authorization: `Token ${DG_API_KEY}` }, perMessageDeflate: false });
  let open = false;
  const q = [];

  dg.on("open", () => { open = true; log("[ASR] Deepgram open"); onOpen?.(); while (q.length) { try { dg.send(q.shift()); } catch {} }});
  dg.on("message", (data) => {
    let msg; try { msg = JSON.parse(data.toString()); } catch { return; }
    onAny?.(msg);
    if (msg.type !== "Results") return;
    const alt = msg.channel?.alternatives?.[0];
    if (!alt) return;
    const txt = (alt.transcript || "").trim();
    if (!txt) return;
    if (msg.is_final || msg.speech_final) { log("[ASR final]", txt); onFinal?.(txt); }
    else { onPartial?.(txt); }
  });
  dg.on("error", (e) => { err("[ASR] error", e?.message || e); onError?.(e); });
  dg.on("close", (c, r) => log("[ASR] closed", c, r?.toString?.() || ""));

  return {
    sendPCM16LE(buf) {
      try { if (open && dg.readyState === 1) dg.send(buf); else q.push(buf); }
      catch (e) { err("[ASR] send error", e?.message || e); }
    },
    close() { try { dg.close(); } catch {} }
  };
}

// ---------- MAKE HELPERS ----------
async function callMake(url, payload, tag) {
  const preview = JSON.stringify(payload);
  log(`[Make ${tag}] POST ${url} body(${preview.length}B):`, preview);
  try {
    const res = await fetch(url, { method: "POST", headers: { "Content-Type": "application/json" }, body: preview });
    const text = await res.text();
    let data; try { data = JSON.parse(text); } catch { data = text; }
    log(`[Make ${tag}] HTTP ${res.status} resp(${text.length}B)`);
    return { ok: res.ok, data, status: res.status };
  } catch (e) { err(`[Make ${tag}] net`, e?.message || e); return { ok: false, data: null, status: 0 }; }
}

// ---------- OPENAI: extraction + NLG (ALL lines model-generated) ----------
async function openaiChat({ system, messages, temperature = 0.3, max_tokens = 180 }) {
  if (!OPENAI_API_KEY) throw new Error("OPENAI_API_KEY missing");
  const body = {
    model: "gpt-4o-mini",
    temperature,
    max_tokens,
    messages: [
      { role: "system", content: system },
      ...messages
    ]
  };
  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: { "Authorization": `Bearer ${OPENAI_API_KEY}`, "Content-Type": "application/json" },
    body: JSON.stringify(body)
  });
  if (!res.ok) throw new Error(`OpenAI ${res.status}: ${await res.text()}`);
  const json = await res.json();
  return json?.choices?.[0]?.message?.content || "";
}

async function extractTurn(utterance, mem, callId, forbidGreet, callerIdGuess) {
  const { nowISO, tz } = nowContext();
  const sys = `
Return ONLY JSON matching this schema. Current time: ${nowISO} ${tz}.
Interpret dates in ${tz}. If caller says “Friday at noon”, resolve ISO start/end (30min).
Fields missing => "".

{
  "intent": "CREATE|READ|DELETE|FAQ|SMALLTALK|UNKNOWN",
  "faq_topic": string,
  "Event_Name": string,
  "Start_Time": string,
  "End_Time": string,
  "Customer_Name": string,
  "Customer_Phone": string,
  "Customer_Email": string,
  "id": string,
  "Notes": string,
  "window": { "start": string, "end": string },
  "ask": "NONE|SERVICE|TIME|NAME|PHONE|CONFIRM",
  "reply": string
}

Guidelines:
- Use booking order: service -> date/time -> check -> name/phone -> finalize.
- Only book Mon–Fri 9–5 (${tz}). If outside hours, ask for an in-hours time.
- Never double-book (we will check availability). If conflict, propose 2 closest alternatives.
- FAQ topics: PRICES|HOURS|SERVICES|LOCATION (or "" if not FAQ).
- If caller agrees after FAQ, set intent=CREATE and ask for SERVICE or TIME as needed.
- Avoid greetings if forbidGreet=true. Use short, varied, conversational phrasing (<= 20 words).
- If we have a phone guess (${callerIdGuess || "none"}), confirm it when asking for phone.
`.trim();

  const userA = `MEM:${JSON.stringify(mem)} CALL:${callId} forbidGreet=${!!forbidGreet} callerGuess=${callerIdGuess || ""}`;
  const raw = await openaiChat({
    system: sys + "\n\n" + AGENT_PROMPT,
    messages: [{ role: "user", content: userA }, { role: "user", content: utterance }],
    temperature: 0.2,
    max_tokens: 220
  });

  let out; try { out = JSON.parse(raw); } catch { out = { intent: "UNKNOWN", ask: "NONE", reply: "" }; }
  log("[extract JSON]", out);
  return out;
}

async function nlgLine(context, forbidGreet) {
  const sys = `
You are a warm front-desk receptionist.
Write ONE short, conversational sentence next (<= 20 words).
Use contractions and small acks. Ask only ONE question (if any).
No greeting if forbidGreet=true. Avoid repeating exact phrasing. Be specific to the current step.
`.trim();
  const content = await openaiChat({
    system: sys + "\n\n" + AGENT_PROMPT,
    messages: [{ role: "user", content: JSON.stringify(context) }],
    temperature: 0.5,
    max_tokens: 60
  });
  return (content || "").replace(/\s+/g, " ").trim();
}

// ---------- TTS: ElevenLabs ----------
async function speakEleven(ws, streamSid, text) {
  if (!streamSid || !text) return;
  if (!ELEVEN_API_KEY || !ELEVEN_VOICE_ID) { log("(!) ELEVEN vars missing — TTS skipped:", text); return; }

  log("[TTS ->]", text);
  let res;
  try {
    const url = `https://api.elevenlabs.io/v1/text-to-speech/${ELEVEN_VOICE_ID}/stream?optimize_streaming_latency=3&output_format=ulaw_8000`;
    res = await fetch(url, {
      method: "POST",
      headers: { "xi-api-key": ELEVEN_API_KEY, "Content-Type": "application/json" },
      body: JSON.stringify({ text, voice_settings: { stability: 0.5, similarity_boost: 0.75 } })
    });
  } catch (e) { err("[TTS] net", e?.message || e); return; }

  if (!res.ok || !res.body) { err("[TTS] HTTP", res.status, await res.text()); return; }

  return new Promise((resolve) => {
    res.body.on("data", (chunk) => {
      try {
        ws.send(JSON.stringify({ event: "media", streamSid, media: { payload: Buffer.from(chunk).toString("base64") } }));
      } catch (e) { err("[TTS] ws send]", e?.message || e); }
    });
    res.body.on("end", () => { log("[TTS] end"); resolve(); });
  });
}

// ---------- EXPRESS + WS (single declarations only) ----------
const app = express();
app.get("/", (_,res)=>res.type("text/plain").send("OK"));
app.get("/twilio", (_,res)=>res.status(426).type("text/plain").send("Upgrade Required: wss://<host>/twilio"));

const server = http.createServer(app);
const wss = new WebSocketServer({ noServer: true, perMessageDeflate: false });

server.on("upgrade", (req, socket, head) => {
  const u = new URL(req.url, `http://${req.headers.host}`);
  if (u.pathname !== "/twilio") { socket.write("HTTP/1.1 404 Not Found\r\n\r\n"); return socket.destroy(); }
  wss.handleUpgrade(req, socket, head, (ws) => wss.emit("connection", ws, req));
});

// ---------- CONVERSATION SESSION ----------
wss.on("connection", (ws) => {
  let streamSid = null;
  let callSid = null;
  let frames = 0;
  let greeted = false;
  let forbidGreet = false;
  let lastUserAt = Date.now();
  let closed = false;
  let pendingSpeak = Promise.resolve();

  // memory/slots (only for context; all lines come from GPT)
  const memory = { name: "", phone: "", email: "", service: "", startISO: "", endISO: "" };

  // ping/pong keepalive
  ws.isAlive = true;
  ws.on("pong", () => { ws.isAlive = true; });
  const pingIv = setInterval(() => {
    if (ws.isAlive === false) { try { ws.terminate(); } catch {} return; }
    ws.isAlive = false;
    try { ws.ping(); } catch {}
  }, 25000);

  // inactivity reprompt (gentle, one line, no greet)
  const INACTIVITY_MS = 10000;
  const repromptIv = setInterval(async () => {
    if (closed) return;
    const idle = Date.now() - lastUserAt;
    if (idle < INACTIVITY_MS) return;

    // pick one gentle reprompt based on what’s missing
    let need = "";
    if (!memory.service) need = "Please ask which service they want.";
    else if (!memory.startISO) need = "Ask what day and time they prefer, suggest an example.";
    else if (!memory.name) need = "Ask for their name.";
    else if (!memory.phone) need = "Ask for phone, confirm caller ID if available.";
    else need = "Confirm booking details in one sentence and ask for permission to book.";

    const line = await nlgLine({ phase: "reprompt", memory, need }, true);
    await say(line);
  }, 3000);

  function digitsOnlyPhone(p) {
    if (!p) return "";
    return (""+p).replace(/\D+/g, "").slice(-10);
  }
  function formatPhone(d10) {
    if (!d10 || d10.length !== 10) return d10 || "";
    return `(${d10.slice(0,3)}) ${d10.slice(3,6)}-${d10.slice(6)}`;
  }

  function callerIdFromStart(evt) {
    // Twilio can pass customParameters or caller info if configured
    const cp = evt?.start?.customParameters || {};
    const maybe =
      cp.caller || cp.from || cp.phone || cp.number || "";
    const d10 = digitsOnlyPhone(maybe);
    return d10 ? formatPhone(d10) : "";
  }

  async function say(text) {
    if (!text || closed) return;
    // serialize TTS to avoid overlap
    pendingSpeak = pendingSpeak.then(() => speakEleven(ws, streamSid, text)).catch(()=>{});
    return pendingSpeak;
  }

  async function finalizeAndHangup(line) {
    if (closed) return;
    closed = true;
    try { await say(line || "Thanks for calling. Goodbye."); } catch {}
    try { ws.send(JSON.stringify({ event: "stop", streamSid })); } catch {}
    cleanup();
    try { ws.close(); } catch {}
  }

  async function handleExtractionResult(ex, utterance, callerGuess) {
    // Merge only as context (model drives conversation)
    if (ex.Customer_Name)  memory.name = ex.Customer_Name.trim();
    if (ex.Customer_Phone) {
      const d = digitsOnlyPhone(ex.Customer_Phone);
      memory.phone = d ? formatPhone(d) : memory.phone;
    }
    if (ex.Customer_Email) memory.email = ex.Customer_Email;
    if (ex.Event_Name)     memory.service = memory.service || (String(ex.Event_Name).toLowerCase().includes("beard") ? "Beard Trim" : "haircut");
    if (ex.Start_Time)     memory.startISO = ex.Start_Time;
    if (ex.End_Time)       memory.endISO = ex.End_Time;

    // CONTROL FLOW (fast paths)
    if (ex.intent === "DELETE") {
      // model must provide id or ask for it via ex.ask
      if (!ex.id) {
        const line = ex.reply || await nlgLine({ need: "Ask for appointment ID to cancel." }, true);
        return say(line);
      }
      const r = await callMake(MAKE_DELETE, { id: ex.id }, "DELETE");
      const line = r.ok
        ? await nlgLine({ inform: "Cancelled successfully. Say goodbye." }, true)
        : await nlgLine({ inform: "Could not cancel. Offer to try again." }, true);
      return finalizeAndHangup(line);
    }

    if (ex.intent === "READ" && (ex.window?.start || memory.startISO)) {
      const win = ex.window?.start
        ? ex.window
        : { start: memory.startISO, end: memory.endISO || memory.startISO };
      const r = await callMake(MAKE_READ, { intent: "READ", window: win }, "READ");
      const count = Array.isArray(r?.data?.events) ? r.data.events.length : 0;
      const line = await nlgLine({ inform: `Found ${count} appointment(s) in that window.`, next: "Offer help." }, true);
      return say(line);
    }

    if (ex.intent === "FAQ") {
      // You can optionally hit MAKE_READ for live FAQ if you mapped it that way.
      if (ex.faq_topic) await callMake(MAKE_READ, { intent: "FAQ", topic: ex.faq_topic }, "FAQ");
      const line = ex.reply || await nlgLine({ faq: ex.faq_topic || "", memory }, true);
      return say(line);
    }

    // CREATE / SMALLTALK / UNKNOWN -> proceed by step
    // enforce business hours if we already have a time
    if (memory.startISO && !isBusinessHours(memory.startISO)) {
      const line = await nlgLine({ gate: "outside_business_hours", tz: LOCAL_TZ }, true);
      return say(line);
    }

    // If we have service+time, check availability
    if (memory.service && memory.startISO && ex.ask !== "NAME" && ex.ask !== "PHONE") {
      const win = { start: memory.startISO, end: memory.endISO || memory.startISO };
      const check = await callMake(MAKE_READ, { intent: "READ", window: win }, "READ-check");
      const events = Array.isArray(check?.data?.events) ? check.data.events : [];
      if (events.length) {
        const line = await nlgLine({ conflict: "time_taken", propose: "2_alternatives" }, true);
        return say(line);
      }
      // prompt for contact if not present
      if (!memory.name) {
        const line = await nlgLine({ ask: "NAME" }, true);
        return say(line);
      }
      if (!memory.phone) {
        const line = await nlgLine({ ask: "PHONE", callerGuess }, true);
        return say(line);
      }
      // confirm finalization
      const line = await nlgLine({ ask: "CONFIRM", memory: { ...memory, pretty: pretty(memory.startISO, LOCAL_TZ) } }, true);
      return say(line);
    }

    // If model wants to ask a particular slot question, honor it
    if (ex.ask && ex.ask !== "NONE") {
      const line = ex.reply || await nlgLine({ ask: ex.ask, memory }, true);
      return say(line);
    }

    // Default: produce one helpful next line
    const line = ex.reply || await nlgLine({ fallback: true, memory }, true);
    return say(line);
  }

  async function runCreateBookingIfConfirmed(utterance) {
    // heuristics for yes/no
    const yes = /\b(yes|yeah|yep|sure|please|go ahead|book it|confirm|sounds good|that works|okay|ok)\b/i.test(utterance || "");
    const no  = /\b(no|nah|nope|stop|wait|hold on|cancel|not now)\b/i.test(utterance || "");
    if (!yes && !no) return false;

    if (no) {
      const line = await nlgLine({ inform: "Not booking. Offer help with another time or service." }, true);
      await say(line);
      return true;
    }

    // Yes → create
    const createReq = {
      Event_Name: memory.service || "Appointment",
      Start_Time: memory.startISO,
      End_Time:   memory.endISO || "",
      Customer_Name:  memory.name,
      Customer_Phone: memory.phone,
      Customer_Email: memory.email || "",
      Notes: `Booked by phone agent. CallSid=${callSid}`
    };
    const when = pretty(memory.startISO, LOCAL_TZ);
    const r = await callMake(MAKE_CREATE, createReq, "CREATE");
    if (r.ok) {
      const line = await nlgLine({ inform: `Booked for ${when}. Thank them and say goodbye.` }, true);
      await finalizeAndHangup(line);
    } else {
      const line = await nlgLine({ inform: "Could not complete booking. Offer to try a different time." }, true);
      await say(line);
    }
    return true;
  }

  async function onUserUtterance(txt) {
    if (closed) return;
    lastUserAt = Date.now();

    // try yes/no fast-path if we’re on confirm step
    const maybeHandled = await runCreateBookingIfConfirmed(txt);
    if (maybeHandled) return;

    // full extraction + step selection
    const callerGuess = memory.phone || ""; // if we parsed earlier
    const ex = await extractTurn(txt, memory, callSid, forbidGreet, callerGuess);
    await handleExtractionResult(ex, txt, callerGuess);
  }

  // ---------- WS handlers ----------
  ws.on("message", async (buf) => {
    let evt; try { evt = JSON.parse(buf.toString()); } catch { return; }

    if (evt.event === "start") {
      streamSid = evt.start?.streamSid || null;
      callSid   = evt.start?.callSid || null;
      const biz = evt.start?.customParameters?.biz || "default";
      log("WS CONNECTED |", streamSid, "| CallSid:", callSid, "| biz:", biz);
      log("[agent] Using AGENT_PROMPT (first 120 chars):", (AGENT_PROMPT.slice(0,120) + "…"));

      // caller ID guess (if provided by your Twilio Stream start event's customParameters)
      const guess = callerIdFromStart(evt);
      if (guess) memory.phone = guess;

      // Deepgram
      const dg = startDeepgram({
        onOpen: () => log("[ASR] ready"),
        onPartial: () => { lastUserAt = Date.now(); },
        onFinal: (txt) => onUserUtterance(txt),
        onError: (e) => err("[ASR] err cb", e?.message || e),
        onAny:   (m) => { if (m.type && m.type !== "Results") log("[ASR msg]", JSON.stringify(m)); }
      });
      ws._dg = dg;

      // greet only once at call start
      if (!greeted) {
        greeted = true;
        forbidGreet = false;
        await say("Hi, thanks for calling Old Line Barbershop. How can I help you today?");
        forbidGreet = true; // prevent future greetings
      }
    }

    else if (evt.event === "media") {
      if (!ws._dg) return;
      frames++;
      if (frames % 50 === 1) log("[media] frames:", frames);
      const b64 = evt.media?.payload;
      if (!b64) return;
      try {
        const ulaw = Buffer.from(b64, "base64");
        const pcm = ulawBufferToPCM16LEBuffer(ulaw);
        ws._dg.sendPCM16LE(pcm);
      } catch (e) { err("[media] decode/send", e?.message || e); }
    }

    else if (evt.event === "stop") {
      log("Twilio stream STOP");
      cleanup();
    }
  });

  function cleanup() {
    if (closed) return;
    try { ws._dg?.close(); } catch {}
    clearInterval(pingIv);
    clearInterval(repromptIv);
    log("WS closed");
  }

  ws.on("close", cleanup);
  ws.on("error", (e) => { err("WS error", e?.message || e); cleanup(); });
});

server.listen(PORT, () => log(`Server running on ${PORT}`));
